The current applications compiled for K80 GPUS are:
      GROMACS/5.1      -> module purge; module load K80 gcc/4.9.3 intel/15.0.0 cuda/7.5 impi/5.1.3.210 mkl/11.3.3 GROMACS/5.1-plumed2.2.3
      GROMACS/5.1.2    -> module purge; module load K80 intel/15.0.0 impi/5.1.3.181 cuda/7.5 mkl/11.2 GROMACS/5.1.2
      GROMACS/2016.3   -> module purge; module load K80 gcc/4.9.4 intel/16.0.2 impi/5.1.3.181 mkl/2017.1 cuda/8.0 GROMACS/2016.3
      GROMACS/2016.5   -> module purge; module load K80 gcc/5.1.0 intel/16.0.2 impi/5.1.3.181 mkl/2017.1 cuda/8.0 GROMACS/2016.5
      NAMD/2.9         -> module purge; module load K80 bullxmpi/bullxmpi-1.2.9.1 cuda/7.5 NAMD/2.9
      AMBER/14         -> module purge; module load K80 intel/16.0.2 bullxmpi/bullxmpi-1.2.9.1 cuda/7.5 mkl/11.3.2 AMBER/14
      AMBER/16	       -> module purge; module load K80 intel/16.0.3 bullxmpi/bullxmpi-1.2.9.1 cuda/7.5 mkl/11.3.3 AMBER/16
      AMBER/18         -> module purge; module load K80 intel/2017.2 bullxmpi/bullxmpi-1.2.9.1 cuda/8.0 mkl/2017.2 python/2.7.10 AMBER/18
      LAMMPS/14May16   -> module purge; module load K80 gcc/4.9.1 intel/16.0.2 bullxmpi/bullxmpi-1.2.9.1 cuda/7.5 mkl/11.3.2 hdf5/1.8.13 lammps/14May16
      PYTHON/2.7.12_ML -> module purge; module load K80 cuda/7.5 mkl/2017.0.098 CUDNN/5.1.3 intel-opencl/2016 python/2.7.12_ML
      PYTHON/3.5.2_ML  -> module purge; module load K80 cuda/7.5 mkl/2017.0.098 CUDNN/5.1.3 python/3.5.2_ML
      PYTHON/3.6.0_ML  -> (DEPRECATED) module purge; module load K80 cuda/7.5 mkl/2017.0.098 CUDNN/5.1.3 intel-opencl/2016 python/3.6.0_ML
      PYTHON/3.6.0+_ML -> module purge; module load K80 cuda/8.0 mkl/2017.1 CUDNN/5.1.10-cuda_8.0 intel-opencl/2016 python/3.6.0+_ML
      PYTHON/3.6.3_ML  -> module purge; module load K80 impi/2018.1 mkl/2018.1 cuda/8.0 CUDNN/7.0.3 python/3.6.3_ML

load impi/2018.1 (PATH, MANPATH, LD_LIBRARY_PATH)
load mkl/2018.1 (LD_LIBRARY_PATH)
load CUDNN/7.0.3 (LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH)
load python/3.6.3_ML (PATH, MANPATH, LD_LIBRARY_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, PYTHONHOME, PYTHONPATH, THEANO_FLAGS)
2019-03-22 04:05:36.261118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:04:00.0
totalMemory: 11.17GiB freeMemory: 11.11GiB
2019-03-22 04:05:36.261192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
slurmstepd: Job 1488767 exceeded memory limit (2054096 > 2048000), being killed
slurmstepd: Exceeded job memory limit
slurmstepd: *** JOB 1488767 ON nvb3 CANCELLED AT 2019-03-22T08:27:41 ***
